{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'draw_nodes_history' from 'utils' (/home/denisaivazov/crawling/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-97a94cae8fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvkprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvkprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcrawling_algorythms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrawler_RC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrawler_RW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrawler_DFS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrawler_BFS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrawler_MOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrawler_MED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETRICS_LIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdraw_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_percentile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdraw_percentile_heatmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdraw_nodes_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdraw_scores_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'draw_nodes_history' from 'utils' (/home/denisaivazov/crawling/src/utils.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from threading import Thread\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "from networkx.algorithms import community\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# my functions implemented in ./src/\n",
    "from vkprint import vkprint\n",
    "from crawling_algorythms import Crawler_RC,Crawler_RW,Crawler_DFS,Crawler_BFS,Crawler_MOD,Crawler_MED, METRICS_LIST\n",
    "from utils import import_graph,draw_graph,get_percentile,draw_percentile_heatmap,draw_nodes_history,draw_scores_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Queue\n",
    "import queue as queue #import queue\n",
    "def treading_crawler(seed_num,big_graph,crawling_method,node_seed,b,percentile_set):\n",
    "    global q\n",
    "    print('thread alive',seed_num,q.qsize())\n",
    "    thread_crawler=crawling_method(big_graph, node_seed = node_seed, budget = b,percentile_set = percentile_set)\n",
    "    \n",
    "    counter = 0\n",
    "    while counter<b:\n",
    "        if counter %1000 == 1:\n",
    "            print(counter,seed_num)\n",
    "        counter+=1\n",
    "        thread_crawler.sampling_process()\n",
    "        #if counter %100:\n",
    "            #print(counter)\n",
    "    #print(seed_num,thread_crawler.observed_history)\n",
    "    #return_dict[seed_num] = thread_crawler.observed_history\n",
    "    vkprint('thread ready',seed_num, q.qsize())\n",
    "    q.put(thread_crawler.observed_history)\n",
    "    print(seed_num,'putted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " big_graph gnutella\n",
      "b= 100 seed count= 8 methods: {'RW': <class 'crawling_algorythms.Crawler_RW'>, 'RC': <class 'crawling_algorythms.Crawler_RC'>, 'DFS': <class 'crawling_algorythms.Crawler_DFS'>, 'BFS': <class 'crawling_algorythms.Crawler_BFS'>, 'MOD': <class 'crawling_algorythms.Crawler_MOD'>, 'MED': <class 'crawling_algorythms.Crawler_MED'>} \n",
      " percentile {'degrees': 13, 'k_cores': 5, 'eccentricity': 24, 'betweenness_centrality': 284783}\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "thread alive 5 0\n",
      "1 3\n",
      "thread alive 4 0\n",
      "thread alive 6 0\n",
      "1 5\n",
      "thread alive 7 0\n",
      "1 4\n",
      "1 6\n",
      "1 7\n",
      " thread ready 0 0\n",
      " thread ready 2 0\n",
      " thread ready 1 0\n",
      " thread ready 5 0\n",
      " thread ready 3 0\n",
      " thread ready 4 0\n",
      " thread ready 6 0\n",
      " thread ready 7 0\n",
      "0 putted\n",
      "5 putted\n",
      "2 putted\n",
      "1 putted\n",
      "4 putted\n",
      "7 putted\n",
      "6 putted\n",
      "3 putted\n",
      " gnutella 8 RW 7  it took  0.024 minutes\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "1 3\n",
      "thread alive 4 0\n",
      "1 4\n",
      "thread alive 5 0\n",
      "1 5\n",
      "thread alive 6 0\n",
      "thread alive 7 0\n",
      "1 6\n",
      "1 7\n",
      " thread ready 1 0\n",
      " thread ready 0 0\n",
      " thread ready 4 0\n",
      " thread ready 2 0\n",
      " thread ready 3 0\n",
      " thread ready 5 0\n",
      " thread ready 7 0\n",
      " thread ready 6 0\n",
      "1 putted\n",
      "0 putted\n",
      "3 putted\n",
      "2 putted\n",
      "4 putted\n",
      "6 putted\n",
      "7 putted\n",
      "5 putted\n",
      " gnutella 8 RC 7  it took  0.007 minutes\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "1 3\n",
      "thread alive 4 0\n",
      "thread alive 5 0\n",
      "1 4\n",
      "1 5\n",
      "thread alive 6 0\n",
      "thread alive 7 0\n",
      "1 6\n",
      "1 7\n",
      " thread ready 2 0\n",
      " thread ready 0 0\n",
      " thread ready 1 0\n",
      " thread ready 4 0\n",
      " thread ready 3 0\n",
      " thread ready 5 0\n",
      " thread ready 6 0\n",
      " thread ready 7 0\n",
      "2 putted\n",
      "0 putted\n",
      "1 putted\n",
      "3 putted\n",
      "4 putted\n",
      "5 putted\n",
      "6 putted\n",
      "7 putted\n",
      " gnutella 8 DFS 7  it took  0.007 minutes\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "thread alive 4 0\n",
      "1 3\n",
      "thread alive 5 0\n",
      "1 5\n",
      "thread alive 6 0\n",
      "1 4\n",
      "1 6\n",
      "thread alive 7 0\n",
      "1 7\n",
      " thread ready 0 0\n",
      " thread ready 2 0\n",
      " thread ready 5 0\n",
      " thread ready 1 0\n",
      " thread ready 3 0\n",
      " thread ready 6 0\n",
      " thread ready 4 0\n",
      "0 putted\n",
      " thread ready 7 0\n",
      "5 putted\n",
      "2 putted\n",
      "1 putted\n",
      "3 putted\n",
      "6 putted\n",
      "4 putted\n",
      "7 putted\n",
      " gnutella 8 BFS 7  it took  0.007 minutes\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "thread alive 4 0\n",
      "1 4\n",
      "1 3\n",
      "thread alive 5 0\n",
      "1 5\n",
      "thread alive 7 0\n",
      "thread alive 6 0\n",
      "1 6\n",
      "1 7\n",
      " thread ready 1 0\n",
      " thread ready 4 0\n",
      " thread ready 3 0\n",
      " thread ready 2 0\n",
      " thread ready 5 0\n",
      " thread ready 6 0\n",
      "1 putted\n",
      " thread ready 0 0\n",
      " thread ready 7 0\n",
      "4 putted\n",
      "3 putted\n",
      "5 putted\n",
      "2 putted\n",
      "6 putted\n",
      "0 putted\n",
      "7 putted\n",
      " gnutella 8 MOD 7  it took  0.01 minutes\n",
      "thread alive 0 0\n",
      "1 0\n",
      "thread alive 1 0\n",
      "1 1\n",
      "thread alive 2 0\n",
      "1 2\n",
      "thread alive 3 0\n",
      "1 3\n",
      "thread alive 4 0\n",
      "1 4\n",
      "thread alive 5 0\n",
      "1 5\n",
      "thread alive 6 0\n",
      "thread alive 7 0\n",
      "1 7\n",
      "1 6\n",
      " thread ready 1 0\n",
      " thread ready 0 0\n",
      " thread ready 3 0\n",
      " thread ready 4 0\n",
      " thread ready 2 0\n",
      " thread ready 5 0\n",
      " thread ready 6 0\n",
      " thread ready 7 0\n",
      "1 putted\n",
      "0 putted\n",
      "3 putted\n",
      "2 putted\n",
      "4 putted\n",
      "7 putted\n",
      "5 putted\n",
      "6 putted\n",
      " gnutella 8 MED 7  it took  0.012 minutes\n",
      "CPU times: user 1.95 s, sys: 440 ms, total: 2.39 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## макропараметры всей задачи\n",
    "graph_name = 'gnutella'\n",
    "methods = {'RW':Crawler_RW,'RC':Crawler_RC,'DFS':Crawler_DFS, 'BFS':Crawler_BFS, \n",
    "              'MOD':Crawler_MOD,'MED':Crawler_MED} #'AFD',\n",
    "b = 100\n",
    "seed_count =8\n",
    "top_percetile = 10\n",
    "\n",
    "# общие множества и вспомогательное, лучше не менять\n",
    "method_color = {'AFD':'pink','RC':'grey','RW':'green','DFS':'black', 'BFS':'blue', 'MED':'cyan','MOD':'red'}\n",
    "graph_name_list = ['importing','wikivote','hamsterster','DCAM','gnutella',  'dblp2010',  'github']  #'slashdot',\n",
    "linestyles = [':', '--', '-.','--']*seed_count\n",
    "\n",
    "\n",
    "# Дальше лучше не трогать\n",
    "t00 = time.time()\n",
    "big_graph = import_graph(graph_name)\n",
    "b = min(big_graph.number_of_nodes(),b)\n",
    "percentile, percentile_set = get_percentile(big_graph,graph_name,top_percetile) # берём топ 10 процентов вершин\n",
    "nx.write_gml(big_graph, \"../data/Graphs/\"+ graph_name +'_BIG.graph')\n",
    "vkprint(\"big_graph \"+graph_name+\"\\nb=\",b,\"seed count=\",seed_count, \"methods:\",methods, \"\\n percentile\",percentile)\n",
    "\n",
    "\n",
    "#draw_graph(big_graph,graph_name) # отрисовываем граф, если не очень большой\n",
    "seeds = random.sample(set(big_graph.nodes),seed_count) # список начальных вершин, по которым мы будем проходиться\n",
    "crawler = dict()   \n",
    "crawler_avg = dict()\n",
    "\n",
    "seeds = random.sample(set(big_graph.nodes),seed_count)\n",
    "history = dict((method, []*seed_count) for method in methods)\n",
    "crawler = dict((method, {'nodes':[],'degrees':[],'k_cores':[],'eccentricity':[],\n",
    "                                  'betweenness_centrality':[]}) for method in methods)\n",
    "crawler_avg = dict((method, {'nodes':[],#np.zeros([len(methods)*seed_count,b+1]),\n",
    "                                  'degrees':[],'k_cores':[],'eccentricity':[],'betweenness_centrality':[]}) for method in methods)\n",
    "\n",
    "\n",
    "\n",
    "# для каждого метода отдельный список тредов, и всё в виде словаря\n",
    "threads =dict()\n",
    "\n",
    "for method in methods:   \n",
    "    #process_queue = list(seeds)    \n",
    "    #while len(process_queue)>0:\n",
    "    crawler_avg[method] = dict({i: np.zeros(b) for i in METRICS_LIST}, **{'nodes': np.zeros(b)})\n",
    "    property_history_hist = {'nodes':[],'degrees':[],'k_cores':[],'eccentricity':[],'betweenness_centrality':[]}\n",
    "    \n",
    "    threads [method] = []\n",
    "    \n",
    "    for seed_num in range(seed_count):\n",
    "        #process_method = process_queue.pop()\n",
    "        t0 =time.time()\n",
    "        #algorythm = methods[method]\n",
    "        \n",
    "        \n",
    "    q = mp.Queue()\n",
    "    for seed_num in range(seed_count):\n",
    "        threads[method].append(mp.Process(daemon = True,target=treading_crawler, args=(seed_num,big_graph,methods[method],seeds[seed_num],b,percentile_set)))\n",
    "        #threads[method][seed_num].setDaemon = True\n",
    "        threads[method][seed_num].start()\n",
    "        \n",
    "    for seed_num in range(seed_count):\n",
    "        history[method].append(q.get())\n",
    "        \n",
    "    q.close()\n",
    "    q.join_thread()    \n",
    "        \n",
    "    for seed_num in range(seed_count):\n",
    "        threads[method][seed_num].join()\n",
    "\n",
    "\n",
    "        for prop in METRICS_LIST:\n",
    "            property_history_hist[prop] = np.array([i for i in history[method][seed_num][prop]])\n",
    "            crawler_avg[method][prop] += property_history_hist[prop]\n",
    "        \n",
    "        crawler_avg[method]['nodes'] += np.array(history[method][seed_num]['nodes'])\n",
    "    vkprint(graph_name, seed_count, method, seed_num,' it took ', round(((time.time() -t0)/60),3),'minutes'  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "draw_nodes_history() missing 2 required positional arguments: 'history' and 'methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d84af9ec1f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdraw_nodes_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: draw_nodes_history() missing 2 required positional arguments: 'history' and 'methods'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "draw_nodes_history() takes 2 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ff4cb275f04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_nodes_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrawler_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_scores_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentile_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: draw_nodes_history() takes 2 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "draw_nodes_history(history,crawler_avg, methods,graph_name,seed_count,method_color)\n",
    "draw_scores_history(percentile_set,methods,graph_name,seed_count,b)\n",
    "\n",
    "\n",
    "\n",
    "draw_percentile_heatmap(percentile_set,graph_name,seed_count,b, normalized=True, venn_on=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i have done everything!!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1918"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vkprint('i have done everything!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
